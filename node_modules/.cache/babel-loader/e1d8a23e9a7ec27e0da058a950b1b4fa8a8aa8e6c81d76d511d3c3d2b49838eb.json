{"ast":null,"code":"import { deflate, inflate } from \"pako\";\nimport { encryptData, decryptData } from \"./encryption\";\n\n// -----------------------------------------------------------------------------\n// byte (binary) strings\n// -----------------------------------------------------------------------------\n\n// fast, Buffer-compatible implem\nexport const toByteString = data => {\n  return new Promise((resolve, reject) => {\n    const blob = typeof data === \"string\" ? new Blob([new TextEncoder().encode(data)]) : new Blob([data instanceof Uint8Array ? data : new Uint8Array(data)]);\n    const reader = new FileReader();\n    reader.onload = event => {\n      if (!event.target || typeof event.target.result !== \"string\") {\n        return reject(new Error(\"couldn't convert to byte string\"));\n      }\n      resolve(event.target.result);\n    };\n    reader.readAsBinaryString(blob);\n  });\n};\nconst byteStringToArrayBuffer = byteString => {\n  const buffer = new ArrayBuffer(byteString.length);\n  const bufferView = new Uint8Array(buffer);\n  for (let i = 0, len = byteString.length; i < len; i++) {\n    bufferView[i] = byteString.charCodeAt(i);\n  }\n  return buffer;\n};\nconst byteStringToString = byteString => {\n  return new TextDecoder(\"utf-8\").decode(byteStringToArrayBuffer(byteString));\n};\n\n// -----------------------------------------------------------------------------\n// base64\n// -----------------------------------------------------------------------------\n\n/**\n * @param isByteString set to true if already byte string to prevent bloat\n *  due to reencoding\n */\nexport const stringToBase64 = async function (str) {\n  let isByteString = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  return isByteString ? window.btoa(str) : window.btoa(await toByteString(str));\n};\n\n// async to align with stringToBase64\nexport const base64ToString = async function (base64) {\n  let isByteString = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n  return isByteString ? window.atob(base64) : byteStringToString(window.atob(base64));\n};\n\n// -----------------------------------------------------------------------------\n// text encoding\n// -----------------------------------------------------------------------------\n/**\n * Encodes (and potentially compresses via zlib) text to byte string\n */\nexport const encode = async _ref => {\n  let {\n    text,\n    compress\n  } = _ref;\n  let deflated;\n  if (compress !== false) {\n    try {\n      deflated = await toByteString(deflate(text));\n    } catch (error) {\n      console.error(\"encode: cannot deflate\", error);\n    }\n  }\n  return {\n    version: \"1\",\n    encoding: \"bstring\",\n    compressed: !!deflated,\n    encoded: deflated || (await toByteString(text))\n  };\n};\nexport const decode = async data => {\n  let decoded;\n  switch (data.encoding) {\n    case \"bstring\":\n      // if compressed, do not double decode the bstring\n      decoded = data.compressed ? data.encoded : await byteStringToString(data.encoded);\n      break;\n    default:\n      throw new Error(`decode: unknown encoding \"${data.encoding}\"`);\n  }\n  if (data.compressed) {\n    return inflate(new Uint8Array(byteStringToArrayBuffer(decoded)), {\n      to: \"string\"\n    });\n  }\n  return decoded;\n};\n\n// -----------------------------------------------------------------------------\n// binary encoding\n// -----------------------------------------------------------------------------\n// -----------------------------------------------------------------------------\nconst CONCAT_BUFFERS_VERSION = 1;\n/** how many bytes we use to encode how many bytes the next chunk has.\n * Corresponds to DataView setter methods (setUint32, setUint16, etc).\n *\n * NOTE ! values must not be changed, which would be backwards incompatible !\n */\nconst VERSION_DATAVIEW_BYTES = 4;\nconst NEXT_CHUNK_SIZE_DATAVIEW_BYTES = 4;\n// -----------------------------------------------------------------------------\n\nconst DATA_VIEW_BITS_MAP = {\n  1: 8,\n  2: 16,\n  4: 32\n};\n\n// getter\n\n// setter\n\n/**\n * abstraction over DataView that serves as a typed getter/setter in case\n * you're using constants for the byte size and want to ensure there's no\n * discrepenancy in the encoding across refactors.\n *\n * DataView serves for an endian-agnostic handling of numbers in ArrayBuffers.\n */\nfunction dataView(buffer, bytes, offset, value) {\n  if (value != null) {\n    if (value > Math.pow(2, DATA_VIEW_BITS_MAP[bytes]) - 1) {\n      throw new Error(`attempting to set value higher than the allocated bytes (value: ${value}, bytes: ${bytes})`);\n    }\n    const method = `setUint${DATA_VIEW_BITS_MAP[bytes]}`;\n    new DataView(buffer.buffer)[method](offset, value);\n    return buffer;\n  }\n  const method = `getUint${DATA_VIEW_BITS_MAP[bytes]}`;\n  return new DataView(buffer.buffer)[method](offset);\n}\n\n// -----------------------------------------------------------------------------\n\n/**\n * Resulting concatenated buffer has this format:\n *\n * [\n *   VERSION chunk (4 bytes)\n *   LENGTH chunk 1 (4 bytes)\n *   DATA chunk 1 (up to 2^32 bits)\n *   LENGTH chunk 2 (4 bytes)\n *   DATA chunk 2 (up to 2^32 bits)\n *   ...\n * ]\n *\n * @param buffers each buffer (chunk) must be at most 2^32 bits large (~4GB)\n */\nconst concatBuffers = function () {\n  for (var _len = arguments.length, buffers = new Array(_len), _key = 0; _key < _len; _key++) {\n    buffers[_key] = arguments[_key];\n  }\n  const bufferView = new Uint8Array(VERSION_DATAVIEW_BYTES + NEXT_CHUNK_SIZE_DATAVIEW_BYTES * buffers.length + buffers.reduce((acc, buffer) => acc + buffer.byteLength, 0));\n  let cursor = 0;\n\n  // as the first chunk we'll encode the version for backwards compatibility\n  dataView(bufferView, VERSION_DATAVIEW_BYTES, cursor, CONCAT_BUFFERS_VERSION);\n  cursor += VERSION_DATAVIEW_BYTES;\n  for (const buffer of buffers) {\n    dataView(bufferView, NEXT_CHUNK_SIZE_DATAVIEW_BYTES, cursor, buffer.byteLength);\n    cursor += NEXT_CHUNK_SIZE_DATAVIEW_BYTES;\n    bufferView.set(buffer, cursor);\n    cursor += buffer.byteLength;\n  }\n  return bufferView;\n};\n\n/** can only be used on buffers created via `concatBuffers()` */\nconst splitBuffers = concatenatedBuffer => {\n  const buffers = [];\n  let cursor = 0;\n\n  // first chunk is the version\n  const version = dataView(concatenatedBuffer, NEXT_CHUNK_SIZE_DATAVIEW_BYTES, cursor);\n  // If version is outside of the supported versions, throw an error.\n  // This usually means the buffer wasn't encoded using this API, so we'd only\n  // waste compute.\n  if (version > CONCAT_BUFFERS_VERSION) {\n    throw new Error(`invalid version ${version}`);\n  }\n  cursor += VERSION_DATAVIEW_BYTES;\n  while (true) {\n    const chunkSize = dataView(concatenatedBuffer, NEXT_CHUNK_SIZE_DATAVIEW_BYTES, cursor);\n    cursor += NEXT_CHUNK_SIZE_DATAVIEW_BYTES;\n    buffers.push(concatenatedBuffer.slice(cursor, cursor + chunkSize));\n    cursor += chunkSize;\n    if (cursor >= concatenatedBuffer.byteLength) {\n      break;\n    }\n  }\n  return buffers;\n};\n\n// helpers for (de)compressing data with JSON metadata including encryption\n// -----------------------------------------------------------------------------\n\n/** @private */\nconst _encryptAndCompress = async (data, encryptionKey) => {\n  const {\n    encryptedBuffer,\n    iv\n  } = await encryptData(encryptionKey, deflate(data));\n  return {\n    iv,\n    buffer: new Uint8Array(encryptedBuffer)\n  };\n};\n\n/**\n * The returned buffer has following format:\n * `[]` refers to a buffers wrapper (see `concatBuffers`)\n *\n * [\n *   encodingMetadataBuffer,\n *   iv,\n *   [\n *      contentsMetadataBuffer\n *      contentsBuffer\n *   ]\n * ]\n */\nexport const compressData = async (dataBuffer, options) => {\n  const fileInfo = {\n    version: 2,\n    compression: \"pako@1\",\n    encryption: \"AES-GCM\"\n  };\n  const encodingMetadataBuffer = new TextEncoder().encode(JSON.stringify(fileInfo));\n  const contentsMetadataBuffer = new TextEncoder().encode(JSON.stringify(options.metadata || null));\n  const {\n    iv,\n    buffer\n  } = await _encryptAndCompress(concatBuffers(contentsMetadataBuffer, dataBuffer), options.encryptionKey);\n  return concatBuffers(encodingMetadataBuffer, iv, buffer);\n};\n\n/** @private */\nconst _decryptAndDecompress = async (iv, decryptedBuffer, decryptionKey, isCompressed) => {\n  decryptedBuffer = new Uint8Array(await decryptData(iv, decryptedBuffer, decryptionKey));\n  if (isCompressed) {\n    return inflate(decryptedBuffer);\n  }\n  return decryptedBuffer;\n};\nexport const decompressData = async (bufferView, options) => {\n  // first chunk is encoding metadata (ignored for now)\n  const [encodingMetadataBuffer, iv, buffer] = splitBuffers(bufferView);\n  const encodingMetadata = JSON.parse(new TextDecoder().decode(encodingMetadataBuffer));\n  try {\n    const [contentsMetadataBuffer, contentsBuffer] = splitBuffers(await _decryptAndDecompress(iv, buffer, options.decryptionKey, !!encodingMetadata.compression));\n    const metadata = JSON.parse(new TextDecoder().decode(contentsMetadataBuffer));\n    return {\n      /** metadata source is always JSON so we can decode it here */\n      metadata,\n      /** data can be anything so the caller must decode it */\n      data: contentsBuffer\n    };\n  } catch (error) {\n    console.error(`Error during decompressing and decrypting the file.`, encodingMetadata);\n    throw error;\n  }\n};\n\n// -----------------------------------------------------------------------------","map":{"version":3,"names":["deflate","inflate","encryptData","decryptData","toByteString","data","Promise","resolve","reject","blob","Blob","TextEncoder","encode","Uint8Array","reader","FileReader","onload","event","target","result","Error","readAsBinaryString","byteStringToArrayBuffer","byteString","buffer","ArrayBuffer","length","bufferView","i","len","charCodeAt","byteStringToString","TextDecoder","decode","stringToBase64","str","isByteString","arguments","undefined","window","btoa","base64ToString","base64","atob","_ref","text","compress","deflated","error","console","version","encoding","compressed","encoded","decoded","to","CONCAT_BUFFERS_VERSION","VERSION_DATAVIEW_BYTES","NEXT_CHUNK_SIZE_DATAVIEW_BYTES","DATA_VIEW_BITS_MAP","dataView","bytes","offset","value","Math","pow","method","DataView","concatBuffers","_len","buffers","Array","_key","reduce","acc","byteLength","cursor","set","splitBuffers","concatenatedBuffer","chunkSize","push","slice","_encryptAndCompress","encryptionKey","encryptedBuffer","iv","compressData","dataBuffer","options","fileInfo","compression","encryption","encodingMetadataBuffer","JSON","stringify","contentsMetadataBuffer","metadata","_decryptAndDecompress","decryptedBuffer","decryptionKey","isCompressed","decompressData","encodingMetadata","parse","contentsBuffer"],"sources":["D:/project/excalidraw-cn/src/data/encode.ts"],"sourcesContent":["import { deflate, inflate } from \"pako\";\nimport { encryptData, decryptData } from \"./encryption\";\n\n// -----------------------------------------------------------------------------\n// byte (binary) strings\n// -----------------------------------------------------------------------------\n\n// fast, Buffer-compatible implem\nexport const toByteString = (\n  data: string | Uint8Array | ArrayBuffer,\n): Promise<string> => {\n  return new Promise((resolve, reject) => {\n    const blob =\n      typeof data === \"string\"\n        ? new Blob([new TextEncoder().encode(data)])\n        : new Blob([data instanceof Uint8Array ? data : new Uint8Array(data)]);\n    const reader = new FileReader();\n    reader.onload = (event) => {\n      if (!event.target || typeof event.target.result !== \"string\") {\n        return reject(new Error(\"couldn't convert to byte string\"));\n      }\n      resolve(event.target.result);\n    };\n    reader.readAsBinaryString(blob);\n  });\n};\n\nconst byteStringToArrayBuffer = (byteString: string) => {\n  const buffer = new ArrayBuffer(byteString.length);\n  const bufferView = new Uint8Array(buffer);\n  for (let i = 0, len = byteString.length; i < len; i++) {\n    bufferView[i] = byteString.charCodeAt(i);\n  }\n  return buffer;\n};\n\nconst byteStringToString = (byteString: string) => {\n  return new TextDecoder(\"utf-8\").decode(byteStringToArrayBuffer(byteString));\n};\n\n// -----------------------------------------------------------------------------\n// base64\n// -----------------------------------------------------------------------------\n\n/**\n * @param isByteString set to true if already byte string to prevent bloat\n *  due to reencoding\n */\nexport const stringToBase64 = async (str: string, isByteString = false) => {\n  return isByteString ? window.btoa(str) : window.btoa(await toByteString(str));\n};\n\n// async to align with stringToBase64\nexport const base64ToString = async (base64: string, isByteString = false) => {\n  return isByteString\n    ? window.atob(base64)\n    : byteStringToString(window.atob(base64));\n};\n\n// -----------------------------------------------------------------------------\n// text encoding\n// -----------------------------------------------------------------------------\n\ntype EncodedData = {\n  encoded: string;\n  encoding: \"bstring\";\n  /** whether text is compressed (zlib) */\n  compressed: boolean;\n  /** version for potential migration purposes */\n  version?: string;\n};\n\n/**\n * Encodes (and potentially compresses via zlib) text to byte string\n */\nexport const encode = async ({\n  text,\n  compress,\n}: {\n  text: string;\n  /** defaults to `true`. If compression fails, falls back to bstring alone. */\n  compress?: boolean;\n}): Promise<EncodedData> => {\n  let deflated!: string;\n  if (compress !== false) {\n    try {\n      deflated = await toByteString(deflate(text));\n    } catch (error: any) {\n      console.error(\"encode: cannot deflate\", error);\n    }\n  }\n  return {\n    version: \"1\",\n    encoding: \"bstring\",\n    compressed: !!deflated,\n    encoded: deflated || (await toByteString(text)),\n  };\n};\n\nexport const decode = async (data: EncodedData): Promise<string> => {\n  let decoded: string;\n\n  switch (data.encoding) {\n    case \"bstring\":\n      // if compressed, do not double decode the bstring\n      decoded = data.compressed\n        ? data.encoded\n        : await byteStringToString(data.encoded);\n      break;\n    default:\n      throw new Error(`decode: unknown encoding \"${data.encoding}\"`);\n  }\n\n  if (data.compressed) {\n    return inflate(new Uint8Array(byteStringToArrayBuffer(decoded)), {\n      to: \"string\",\n    });\n  }\n\n  return decoded;\n};\n\n// -----------------------------------------------------------------------------\n// binary encoding\n// -----------------------------------------------------------------------------\n\ntype FileEncodingInfo = {\n  /* version 2 is the version we're shipping the initial image support with.\n    version 1 was a PR version that a lot of people were using anyway.\n    Thus, if there are issues we can check whether they're not using the\n    unoffic version */\n  version: 1 | 2;\n  compression: \"pako@1\" | null;\n  encryption: \"AES-GCM\" | null;\n};\n\n// -----------------------------------------------------------------------------\nconst CONCAT_BUFFERS_VERSION = 1;\n/** how many bytes we use to encode how many bytes the next chunk has.\n * Corresponds to DataView setter methods (setUint32, setUint16, etc).\n *\n * NOTE ! values must not be changed, which would be backwards incompatible !\n */\nconst VERSION_DATAVIEW_BYTES = 4;\nconst NEXT_CHUNK_SIZE_DATAVIEW_BYTES = 4;\n// -----------------------------------------------------------------------------\n\nconst DATA_VIEW_BITS_MAP = { 1: 8, 2: 16, 4: 32 } as const;\n\n// getter\nfunction dataView(buffer: Uint8Array, bytes: 1 | 2 | 4, offset: number): number;\n// setter\nfunction dataView(\n  buffer: Uint8Array,\n  bytes: 1 | 2 | 4,\n  offset: number,\n  value: number,\n): Uint8Array;\n/**\n * abstraction over DataView that serves as a typed getter/setter in case\n * you're using constants for the byte size and want to ensure there's no\n * discrepenancy in the encoding across refactors.\n *\n * DataView serves for an endian-agnostic handling of numbers in ArrayBuffers.\n */\nfunction dataView(\n  buffer: Uint8Array,\n  bytes: 1 | 2 | 4,\n  offset: number,\n  value?: number,\n): Uint8Array | number {\n  if (value != null) {\n    if (value > Math.pow(2, DATA_VIEW_BITS_MAP[bytes]) - 1) {\n      throw new Error(\n        `attempting to set value higher than the allocated bytes (value: ${value}, bytes: ${bytes})`,\n      );\n    }\n    const method = `setUint${DATA_VIEW_BITS_MAP[bytes]}` as const;\n    new DataView(buffer.buffer)[method](offset, value);\n    return buffer;\n  }\n  const method = `getUint${DATA_VIEW_BITS_MAP[bytes]}` as const;\n  return new DataView(buffer.buffer)[method](offset);\n}\n\n// -----------------------------------------------------------------------------\n\n/**\n * Resulting concatenated buffer has this format:\n *\n * [\n *   VERSION chunk (4 bytes)\n *   LENGTH chunk 1 (4 bytes)\n *   DATA chunk 1 (up to 2^32 bits)\n *   LENGTH chunk 2 (4 bytes)\n *   DATA chunk 2 (up to 2^32 bits)\n *   ...\n * ]\n *\n * @param buffers each buffer (chunk) must be at most 2^32 bits large (~4GB)\n */\nconst concatBuffers = (...buffers: Uint8Array[]) => {\n  const bufferView = new Uint8Array(\n    VERSION_DATAVIEW_BYTES +\n      NEXT_CHUNK_SIZE_DATAVIEW_BYTES * buffers.length +\n      buffers.reduce((acc, buffer) => acc + buffer.byteLength, 0),\n  );\n\n  let cursor = 0;\n\n  // as the first chunk we'll encode the version for backwards compatibility\n  dataView(bufferView, VERSION_DATAVIEW_BYTES, cursor, CONCAT_BUFFERS_VERSION);\n  cursor += VERSION_DATAVIEW_BYTES;\n\n  for (const buffer of buffers) {\n    dataView(\n      bufferView,\n      NEXT_CHUNK_SIZE_DATAVIEW_BYTES,\n      cursor,\n      buffer.byteLength,\n    );\n    cursor += NEXT_CHUNK_SIZE_DATAVIEW_BYTES;\n\n    bufferView.set(buffer, cursor);\n    cursor += buffer.byteLength;\n  }\n\n  return bufferView;\n};\n\n/** can only be used on buffers created via `concatBuffers()` */\nconst splitBuffers = (concatenatedBuffer: Uint8Array) => {\n  const buffers = [];\n\n  let cursor = 0;\n\n  // first chunk is the version\n  const version = dataView(\n    concatenatedBuffer,\n    NEXT_CHUNK_SIZE_DATAVIEW_BYTES,\n    cursor,\n  );\n  // If version is outside of the supported versions, throw an error.\n  // This usually means the buffer wasn't encoded using this API, so we'd only\n  // waste compute.\n  if (version > CONCAT_BUFFERS_VERSION) {\n    throw new Error(`invalid version ${version}`);\n  }\n\n  cursor += VERSION_DATAVIEW_BYTES;\n\n  while (true) {\n    const chunkSize = dataView(\n      concatenatedBuffer,\n      NEXT_CHUNK_SIZE_DATAVIEW_BYTES,\n      cursor,\n    );\n    cursor += NEXT_CHUNK_SIZE_DATAVIEW_BYTES;\n\n    buffers.push(concatenatedBuffer.slice(cursor, cursor + chunkSize));\n    cursor += chunkSize;\n    if (cursor >= concatenatedBuffer.byteLength) {\n      break;\n    }\n  }\n\n  return buffers;\n};\n\n// helpers for (de)compressing data with JSON metadata including encryption\n// -----------------------------------------------------------------------------\n\n/** @private */\nconst _encryptAndCompress = async (\n  data: Uint8Array | string,\n  encryptionKey: string,\n) => {\n  const { encryptedBuffer, iv } = await encryptData(\n    encryptionKey,\n    deflate(data),\n  );\n\n  return { iv, buffer: new Uint8Array(encryptedBuffer) };\n};\n\n/**\n * The returned buffer has following format:\n * `[]` refers to a buffers wrapper (see `concatBuffers`)\n *\n * [\n *   encodingMetadataBuffer,\n *   iv,\n *   [\n *      contentsMetadataBuffer\n *      contentsBuffer\n *   ]\n * ]\n */\nexport const compressData = async <T extends Record<string, any> = never>(\n  dataBuffer: Uint8Array,\n  options: {\n    encryptionKey: string;\n  } & ([T] extends [never]\n    ? {\n        metadata?: T;\n      }\n    : {\n        metadata: T;\n      }),\n): Promise<Uint8Array> => {\n  const fileInfo: FileEncodingInfo = {\n    version: 2,\n    compression: \"pako@1\",\n    encryption: \"AES-GCM\",\n  };\n\n  const encodingMetadataBuffer = new TextEncoder().encode(\n    JSON.stringify(fileInfo),\n  );\n\n  const contentsMetadataBuffer = new TextEncoder().encode(\n    JSON.stringify(options.metadata || null),\n  );\n\n  const { iv, buffer } = await _encryptAndCompress(\n    concatBuffers(contentsMetadataBuffer, dataBuffer),\n    options.encryptionKey,\n  );\n\n  return concatBuffers(encodingMetadataBuffer, iv, buffer);\n};\n\n/** @private */\nconst _decryptAndDecompress = async (\n  iv: Uint8Array,\n  decryptedBuffer: Uint8Array,\n  decryptionKey: string,\n  isCompressed: boolean,\n) => {\n  decryptedBuffer = new Uint8Array(\n    await decryptData(iv, decryptedBuffer, decryptionKey),\n  );\n\n  if (isCompressed) {\n    return inflate(decryptedBuffer);\n  }\n\n  return decryptedBuffer;\n};\n\nexport const decompressData = async <T extends Record<string, any>>(\n  bufferView: Uint8Array,\n  options: { decryptionKey: string },\n) => {\n  // first chunk is encoding metadata (ignored for now)\n  const [encodingMetadataBuffer, iv, buffer] = splitBuffers(bufferView);\n\n  const encodingMetadata: FileEncodingInfo = JSON.parse(\n    new TextDecoder().decode(encodingMetadataBuffer),\n  );\n\n  try {\n    const [contentsMetadataBuffer, contentsBuffer] = splitBuffers(\n      await _decryptAndDecompress(\n        iv,\n        buffer,\n        options.decryptionKey,\n        !!encodingMetadata.compression,\n      ),\n    );\n\n    const metadata = JSON.parse(\n      new TextDecoder().decode(contentsMetadataBuffer),\n    ) as T;\n\n    return {\n      /** metadata source is always JSON so we can decode it here */\n      metadata,\n      /** data can be anything so the caller must decode it */\n      data: contentsBuffer,\n    };\n  } catch (error: any) {\n    console.error(\n      `Error during decompressing and decrypting the file.`,\n      encodingMetadata,\n    );\n    throw error;\n  }\n};\n\n// -----------------------------------------------------------------------------\n"],"mappings":"AAAA,SAASA,OAAO,EAAEC,OAAO,QAAQ,MAAM;AACvC,SAASC,WAAW,EAAEC,WAAW,QAAQ,cAAc;;AAEvD;AACA;AACA;;AAEA;AACA,OAAO,MAAMC,YAAY,GACvBC,IAAuC,IACnB;EACpB,OAAO,IAAIC,OAAO,CAAC,CAACC,OAAO,EAAEC,MAAM,KAAK;IACtC,MAAMC,IAAI,GACR,OAAOJ,IAAI,KAAK,QAAQ,GACpB,IAAIK,IAAI,CAAC,CAAC,IAAIC,WAAW,EAAE,CAACC,MAAM,CAACP,IAAI,CAAC,CAAC,CAAC,GAC1C,IAAIK,IAAI,CAAC,CAACL,IAAI,YAAYQ,UAAU,GAAGR,IAAI,GAAG,IAAIQ,UAAU,CAACR,IAAI,CAAC,CAAC,CAAC;IAC1E,MAAMS,MAAM,GAAG,IAAIC,UAAU,EAAE;IAC/BD,MAAM,CAACE,MAAM,GAAIC,KAAK,IAAK;MACzB,IAAI,CAACA,KAAK,CAACC,MAAM,IAAI,OAAOD,KAAK,CAACC,MAAM,CAACC,MAAM,KAAK,QAAQ,EAAE;QAC5D,OAAOX,MAAM,CAAC,IAAIY,KAAK,CAAC,iCAAiC,CAAC,CAAC;MAC7D;MACAb,OAAO,CAACU,KAAK,CAACC,MAAM,CAACC,MAAM,CAAC;IAC9B,CAAC;IACDL,MAAM,CAACO,kBAAkB,CAACZ,IAAI,CAAC;EACjC,CAAC,CAAC;AACJ,CAAC;AAED,MAAMa,uBAAuB,GAAIC,UAAkB,IAAK;EACtD,MAAMC,MAAM,GAAG,IAAIC,WAAW,CAACF,UAAU,CAACG,MAAM,CAAC;EACjD,MAAMC,UAAU,GAAG,IAAId,UAAU,CAACW,MAAM,CAAC;EACzC,KAAK,IAAII,CAAC,GAAG,CAAC,EAAEC,GAAG,GAAGN,UAAU,CAACG,MAAM,EAAEE,CAAC,GAAGC,GAAG,EAAED,CAAC,EAAE,EAAE;IACrDD,UAAU,CAACC,CAAC,CAAC,GAAGL,UAAU,CAACO,UAAU,CAACF,CAAC,CAAC;EAC1C;EACA,OAAOJ,MAAM;AACf,CAAC;AAED,MAAMO,kBAAkB,GAAIR,UAAkB,IAAK;EACjD,OAAO,IAAIS,WAAW,CAAC,OAAO,CAAC,CAACC,MAAM,CAACX,uBAAuB,CAACC,UAAU,CAAC,CAAC;AAC7E,CAAC;;AAED;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA,OAAO,MAAMW,cAAc,GAAG,eAAAA,CAAOC,GAAW,EAA2B;EAAA,IAAzBC,YAAY,GAAAC,SAAA,CAAAX,MAAA,QAAAW,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,KAAK;EACpE,OAAOD,YAAY,GAAGG,MAAM,CAACC,IAAI,CAACL,GAAG,CAAC,GAAGI,MAAM,CAACC,IAAI,CAAC,MAAMpC,YAAY,CAAC+B,GAAG,CAAC,CAAC;AAC/E,CAAC;;AAED;AACA,OAAO,MAAMM,cAAc,GAAG,eAAAA,CAAOC,MAAc,EAA2B;EAAA,IAAzBN,YAAY,GAAAC,SAAA,CAAAX,MAAA,QAAAW,SAAA,QAAAC,SAAA,GAAAD,SAAA,MAAG,KAAK;EACvE,OAAOD,YAAY,GACfG,MAAM,CAACI,IAAI,CAACD,MAAM,CAAC,GACnBX,kBAAkB,CAACQ,MAAM,CAACI,IAAI,CAACD,MAAM,CAAC,CAAC;AAC7C,CAAC;;AAED;AACA;AACA;AAWA;AACA;AACA;AACA,OAAO,MAAM9B,MAAM,GAAG,MAAAgC,IAAA,IAOM;EAAA,IAPC;IAC3BC,IAAI;IACJC;EAKF,CAAC,GAAAF,IAAA;EACC,IAAIG,QAAiB;EACrB,IAAID,QAAQ,KAAK,KAAK,EAAE;IACtB,IAAI;MACFC,QAAQ,GAAG,MAAM3C,YAAY,CAACJ,OAAO,CAAC6C,IAAI,CAAC,CAAC;IAC9C,CAAC,CAAC,OAAOG,KAAU,EAAE;MACnBC,OAAO,CAACD,KAAK,CAAC,wBAAwB,EAAEA,KAAK,CAAC;IAChD;EACF;EACA,OAAO;IACLE,OAAO,EAAE,GAAG;IACZC,QAAQ,EAAE,SAAS;IACnBC,UAAU,EAAE,CAAC,CAACL,QAAQ;IACtBM,OAAO,EAAEN,QAAQ,KAAK,MAAM3C,YAAY,CAACyC,IAAI,CAAC;EAChD,CAAC;AACH,CAAC;AAED,OAAO,MAAMZ,MAAM,GAAG,MAAO5B,IAAiB,IAAsB;EAClE,IAAIiD,OAAe;EAEnB,QAAQjD,IAAI,CAAC8C,QAAQ;IACnB,KAAK,SAAS;MACZ;MACAG,OAAO,GAAGjD,IAAI,CAAC+C,UAAU,GACrB/C,IAAI,CAACgD,OAAO,GACZ,MAAMtB,kBAAkB,CAAC1B,IAAI,CAACgD,OAAO,CAAC;MAC1C;IACF;MACE,MAAM,IAAIjC,KAAK,CAAE,6BAA4Bf,IAAI,CAAC8C,QAAS,GAAE,CAAC;EAAC;EAGnE,IAAI9C,IAAI,CAAC+C,UAAU,EAAE;IACnB,OAAOnD,OAAO,CAAC,IAAIY,UAAU,CAACS,uBAAuB,CAACgC,OAAO,CAAC,CAAC,EAAE;MAC/DC,EAAE,EAAE;IACN,CAAC,CAAC;EACJ;EAEA,OAAOD,OAAO;AAChB,CAAC;;AAED;AACA;AACA;AAYA;AACA,MAAME,sBAAsB,GAAG,CAAC;AAChC;AACA;AACA;AACA;AACA;AACA,MAAMC,sBAAsB,GAAG,CAAC;AAChC,MAAMC,8BAA8B,GAAG,CAAC;AACxC;;AAEA,MAAMC,kBAAkB,GAAG;EAAE,CAAC,EAAE,CAAC;EAAE,CAAC,EAAE,EAAE;EAAE,CAAC,EAAE;AAAG,CAAU;;AAE1D;;AAEA;;AAOA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASC,QAAQA,CACfpC,MAAkB,EAClBqC,KAAgB,EAChBC,MAAc,EACdC,KAAc,EACO;EACrB,IAAIA,KAAK,IAAI,IAAI,EAAE;IACjB,IAAIA,KAAK,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,EAAEN,kBAAkB,CAACE,KAAK,CAAC,CAAC,GAAG,CAAC,EAAE;MACtD,MAAM,IAAIzC,KAAK,CACZ,mEAAkE2C,KAAM,YAAWF,KAAM,GAAE,CAC7F;IACH;IACA,MAAMK,MAAM,GAAI,UAASP,kBAAkB,CAACE,KAAK,CAAE,EAAU;IAC7D,IAAIM,QAAQ,CAAC3C,MAAM,CAACA,MAAM,CAAC,CAAC0C,MAAM,CAAC,CAACJ,MAAM,EAAEC,KAAK,CAAC;IAClD,OAAOvC,MAAM;EACf;EACA,MAAM0C,MAAM,GAAI,UAASP,kBAAkB,CAACE,KAAK,CAAE,EAAU;EAC7D,OAAO,IAAIM,QAAQ,CAAC3C,MAAM,CAACA,MAAM,CAAC,CAAC0C,MAAM,CAAC,CAACJ,MAAM,CAAC;AACpD;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,MAAMM,aAAa,GAAG,SAAAA,CAAA,EAA8B;EAAA,SAAAC,IAAA,GAAAhC,SAAA,CAAAX,MAAA,EAA1B4C,OAAO,OAAAC,KAAA,CAAAF,IAAA,GAAAG,IAAA,MAAAA,IAAA,GAAAH,IAAA,EAAAG,IAAA;IAAPF,OAAO,CAAAE,IAAA,IAAAnC,SAAA,CAAAmC,IAAA;EAAA;EAC/B,MAAM7C,UAAU,GAAG,IAAId,UAAU,CAC/B4C,sBAAsB,GACpBC,8BAA8B,GAAGY,OAAO,CAAC5C,MAAM,GAC/C4C,OAAO,CAACG,MAAM,CAAC,CAACC,GAAG,EAAElD,MAAM,KAAKkD,GAAG,GAAGlD,MAAM,CAACmD,UAAU,EAAE,CAAC,CAAC,CAC9D;EAED,IAAIC,MAAM,GAAG,CAAC;;EAEd;EACAhB,QAAQ,CAACjC,UAAU,EAAE8B,sBAAsB,EAAEmB,MAAM,EAAEpB,sBAAsB,CAAC;EAC5EoB,MAAM,IAAInB,sBAAsB;EAEhC,KAAK,MAAMjC,MAAM,IAAI8C,OAAO,EAAE;IAC5BV,QAAQ,CACNjC,UAAU,EACV+B,8BAA8B,EAC9BkB,MAAM,EACNpD,MAAM,CAACmD,UAAU,CAClB;IACDC,MAAM,IAAIlB,8BAA8B;IAExC/B,UAAU,CAACkD,GAAG,CAACrD,MAAM,EAAEoD,MAAM,CAAC;IAC9BA,MAAM,IAAIpD,MAAM,CAACmD,UAAU;EAC7B;EAEA,OAAOhD,UAAU;AACnB,CAAC;;AAED;AACA,MAAMmD,YAAY,GAAIC,kBAA8B,IAAK;EACvD,MAAMT,OAAO,GAAG,EAAE;EAElB,IAAIM,MAAM,GAAG,CAAC;;EAEd;EACA,MAAM1B,OAAO,GAAGU,QAAQ,CACtBmB,kBAAkB,EAClBrB,8BAA8B,EAC9BkB,MAAM,CACP;EACD;EACA;EACA;EACA,IAAI1B,OAAO,GAAGM,sBAAsB,EAAE;IACpC,MAAM,IAAIpC,KAAK,CAAE,mBAAkB8B,OAAQ,EAAC,CAAC;EAC/C;EAEA0B,MAAM,IAAInB,sBAAsB;EAEhC,OAAO,IAAI,EAAE;IACX,MAAMuB,SAAS,GAAGpB,QAAQ,CACxBmB,kBAAkB,EAClBrB,8BAA8B,EAC9BkB,MAAM,CACP;IACDA,MAAM,IAAIlB,8BAA8B;IAExCY,OAAO,CAACW,IAAI,CAACF,kBAAkB,CAACG,KAAK,CAACN,MAAM,EAAEA,MAAM,GAAGI,SAAS,CAAC,CAAC;IAClEJ,MAAM,IAAII,SAAS;IACnB,IAAIJ,MAAM,IAAIG,kBAAkB,CAACJ,UAAU,EAAE;MAC3C;IACF;EACF;EAEA,OAAOL,OAAO;AAChB,CAAC;;AAED;AACA;;AAEA;AACA,MAAMa,mBAAmB,GAAG,MAAAA,CAC1B9E,IAAyB,EACzB+E,aAAqB,KAClB;EACH,MAAM;IAAEC,eAAe;IAAEC;EAAG,CAAC,GAAG,MAAMpF,WAAW,CAC/CkF,aAAa,EACbpF,OAAO,CAACK,IAAI,CAAC,CACd;EAED,OAAO;IAAEiF,EAAE;IAAE9D,MAAM,EAAE,IAAIX,UAAU,CAACwE,eAAe;EAAE,CAAC;AACxD,CAAC;;AAED;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,MAAME,YAAY,GAAG,MAAAA,CAC1BC,UAAsB,EACtBC,OAQM,KACkB;EACxB,MAAMC,QAA0B,GAAG;IACjCxC,OAAO,EAAE,CAAC;IACVyC,WAAW,EAAE,QAAQ;IACrBC,UAAU,EAAE;EACd,CAAC;EAED,MAAMC,sBAAsB,GAAG,IAAIlF,WAAW,EAAE,CAACC,MAAM,CACrDkF,IAAI,CAACC,SAAS,CAACL,QAAQ,CAAC,CACzB;EAED,MAAMM,sBAAsB,GAAG,IAAIrF,WAAW,EAAE,CAACC,MAAM,CACrDkF,IAAI,CAACC,SAAS,CAACN,OAAO,CAACQ,QAAQ,IAAI,IAAI,CAAC,CACzC;EAED,MAAM;IAAEX,EAAE;IAAE9D;EAAO,CAAC,GAAG,MAAM2D,mBAAmB,CAC9Cf,aAAa,CAAC4B,sBAAsB,EAAER,UAAU,CAAC,EACjDC,OAAO,CAACL,aAAa,CACtB;EAED,OAAOhB,aAAa,CAACyB,sBAAsB,EAAEP,EAAE,EAAE9D,MAAM,CAAC;AAC1D,CAAC;;AAED;AACA,MAAM0E,qBAAqB,GAAG,MAAAA,CAC5BZ,EAAc,EACda,eAA2B,EAC3BC,aAAqB,EACrBC,YAAqB,KAClB;EACHF,eAAe,GAAG,IAAItF,UAAU,CAC9B,MAAMV,WAAW,CAACmF,EAAE,EAAEa,eAAe,EAAEC,aAAa,CAAC,CACtD;EAED,IAAIC,YAAY,EAAE;IAChB,OAAOpG,OAAO,CAACkG,eAAe,CAAC;EACjC;EAEA,OAAOA,eAAe;AACxB,CAAC;AAED,OAAO,MAAMG,cAAc,GAAG,MAAAA,CAC5B3E,UAAsB,EACtB8D,OAAkC,KAC/B;EACH;EACA,MAAM,CAACI,sBAAsB,EAAEP,EAAE,EAAE9D,MAAM,CAAC,GAAGsD,YAAY,CAACnD,UAAU,CAAC;EAErE,MAAM4E,gBAAkC,GAAGT,IAAI,CAACU,KAAK,CACnD,IAAIxE,WAAW,EAAE,CAACC,MAAM,CAAC4D,sBAAsB,CAAC,CACjD;EAED,IAAI;IACF,MAAM,CAACG,sBAAsB,EAAES,cAAc,CAAC,GAAG3B,YAAY,CAC3D,MAAMoB,qBAAqB,CACzBZ,EAAE,EACF9D,MAAM,EACNiE,OAAO,CAACW,aAAa,EACrB,CAAC,CAACG,gBAAgB,CAACZ,WAAW,CAC/B,CACF;IAED,MAAMM,QAAQ,GAAGH,IAAI,CAACU,KAAK,CACzB,IAAIxE,WAAW,EAAE,CAACC,MAAM,CAAC+D,sBAAsB,CAAC,CAC5C;IAEN,OAAO;MACL;MACAC,QAAQ;MACR;MACA5F,IAAI,EAAEoG;IACR,CAAC;EACH,CAAC,CAAC,OAAOzD,KAAU,EAAE;IACnBC,OAAO,CAACD,KAAK,CACV,qDAAoD,EACrDuD,gBAAgB,CACjB;IACD,MAAMvD,KAAK;EACb;AACF,CAAC;;AAED"},"metadata":{},"sourceType":"module","externalDependencies":[]}